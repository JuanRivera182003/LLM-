# Proyecto NLP RoboCup ‚Äî Tokenizaci√≥n, Clasificaci√≥n y Planificaci√≥n (BERT + T5)

Este repositorio contiene el desarrollo de un sistema de comprensi√≥n y planificaci√≥n de lenguaje natural aplicado al dominio **RoboCup@Home**.  

El proyecto combina **clasificaci√≥n de tokens (NER)** con **modelos de planificaci√≥n secuencial (T5)**, permitiendo convertir instrucciones humanas en estructuras comprensibles por el robot.

---

## üìÅ Estructura del repositorio

```
.
‚îú‚îÄ‚îÄ bert_token_classification_model/
‚îÇ   ‚îî‚îÄ‚îÄ checkpoint-339/              ‚Üí Pesos del modelo BERT fine-tuneado para clasificaci√≥n de tokens
‚îú‚îÄ‚îÄ t5_plan_model/
‚îÇ   ‚îî‚îÄ‚îÄ ...                          ‚Üí Pesos del modelo T5 para planificaci√≥n
‚îú‚îÄ‚îÄ Ruta.ipynb                       ‚Üí Notebook principal: flujo de entrenamiento y evaluaci√≥n de modelos
‚îú‚îÄ‚îÄ Tokenizar.ipynb                  ‚Üí Notebook de tokenizaci√≥n y preprocesamiento de dataset
‚îú‚îÄ‚îÄ dataset.jsonl                    ‚Üí Dataset base (formato JSON Lines)
‚îú‚îÄ‚îÄ dataset_for_t5.csv               ‚Üí Dataset adaptado para entrenamiento del T5
‚îú‚îÄ‚îÄ dataset_with_slots.jsonl         ‚Üí Dataset enriquecido con ‚Äúslots‚Äù sem√°nticos
‚îú‚îÄ‚îÄ dataset_with_slots_and_plan.jsonl‚Üí Dataset con slots + plan completo
‚îú‚îÄ‚îÄ .gitattributes                   ‚Üí Configuraci√≥n de Git LFS (para subir modelos grandes)
‚îú‚îÄ‚îÄ requirements.txt                 ‚Üí Dependencias principales del proyecto
‚îî‚îÄ‚îÄ README.md                        ‚Üí Este documento
```

---

## ‚öôÔ∏è Requisitos e instalaci√≥n

### 1. Instalar dependencias

Crea el entorno virtual y luego instala las librer√≠as necesarias:

```bash
python -m venv venv
source venv/bin/activate   # En Linux / macOS
venv\Scripts\activate      # En Windows

pip install -r requirements.txt
```

Si a√∫n no tienes el archivo `requirements.txt`, crea uno con este contenido:

```text
torch>=2.0.0
transformers>=4.38.0
datasets>=2.18.0
pandas
numpy
scikit-learn
tqdm
```

## Descripci√≥n t√©cnica

### 1. Tokenizaci√≥n y Clasificaci√≥n (BERT)
- Modelo base: `bert-base-cased`
- Tarea: **Token Classification / NER**
- Entrenado en los datasets JSONL con etiquetas de comandos RoboCup.
- Objetivo: identificar entidades como **acci√≥n**, **objeto**, **ubicaci√≥n**, **agente**, etc.

### 2. Planificaci√≥n Secuencial (T5)
- Modelo base: `t5-small`
- Tarea: **Conditional Text Generation**
- Entrada: texto anotado con los ‚Äúslots‚Äù generados por el modelo BERT.
- Salida: **plan estructurado** para el robot (ej. `go(kitchen); grasp(cup); return(table)`).

---

## Flujo de trabajo

1. **Tokenizar y etiquetar texto** con `Tokenizar.ipynb`
   - Limpieza y divisi√≥n del dataset.
   - Entrenamiento o carga del modelo BERT.
   - Predicci√≥n de etiquetas por token.

2. **Generar dataset estructurado** (`dataset_with_slots.jsonl`)
   - A partir de las etiquetas anteriores, construir pares entrada‚Äìsalida para el modelo T5.

3. **Entrenar planificador (T5)** con `Ruta.ipynb`
   - Entrenamiento del modelo T5.
   - Evaluaci√≥n y pruebas de generaci√≥n de secuencias.

4. **Ejecutar inferencia final**
   ```python
   from transformers import AutoTokenizer, AutoModelForTokenClassification, T5Tokenizer, T5ForConditionalGeneration

   # === Tokenizaci√≥n ===
   tok = AutoTokenizer.from_pretrained("bert_token_classification_model/checkpoint-339")
   model = AutoModelForTokenClassification.from_pretrained("bert_token_classification_model/checkpoint-339")

   inputs = tok("Bring me the red cup from the kitchen", return_tensors="pt")
   outputs = model(**inputs)
   # Procesar logits para obtener etiquetas

   # === Planificaci√≥n ===
   t5_tok = T5Tokenizer.from_pretrained("t5_plan_model")
   t5_model = T5ForConditionalGeneration.from_pretrained("t5_plan_model")

   plan_in = "action: bring; object: cup; color: red; location: kitchen"
   plan_ids = t5_model.generate(t5_tok(plan_in, return_tensors="pt").input_ids)
   print(t5_tok.decode(plan_ids[0], skip_special_tokens=True))
   ```

---

## Referencia RoboCup ‚Äî Generador de Comandos

Este trabajo se basa en el **Generador de Comandos** del repositorio oficial de RoboCup@Home, disponible en:

üîó [https://github.com/RoboCupAtHome/command-generator](https://github.com/RoboCupAtHome/CommandGenerator)

All√≠ se defini√≥ la estructura base de **slots** y **plantillas de comandos**.

---

## üí° Notas adicionales

- Los notebooks fueron limpiados de metadatos para visualizar correctamente en GitHub.  
- Los modelos grandes usan [Git LFS](https://git-lfs.github.com/).  

---
